{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f771e54",
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'\n",
    "\n",
    "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38553ab",
   "metadata": {},
   "source": [
    "!unzip -q train.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f35ae81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(len(os.listdir('./data/dogs-vs-cats-redux-kernels-edition/train/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c002e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce3200a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir('./data/dogs-vs-cats-redux-kernels-edition/train/'):\n",
    "    if 'cat' in i:\n",
    "        shutil.copyfile('./data/dogs-vs-cats-redux-kernels-edition/train/' + i, './data/dogs-vs-cats-redux-kernels-edition/cat/' + i)\n",
    "    if 'dog' in i:\n",
    "        shutil.copyfile('./data/dogs-vs-cats-redux-kernels-edition/train/' + i, './data/dogs-vs-cats-redux-kernels-edition/dog/' + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24afda92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "<BatchDataset shapes: ((None, 64, 64, 3), (None,)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    './data/dataset/',\n",
    "    image_size=(64,64),\n",
    "    batch_size=64,\n",
    "    subset='training',\n",
    "    validation_split=0.2,\n",
    "    seed=1234\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    './data/dataset/',\n",
    "    image_size=(64,64),\n",
    "    batch_size=64,\n",
    "    subset='validation',\n",
    "    validation_split=0.2,\n",
    "    seed=1234\n",
    ")\n",
    "\n",
    "print(train_ds)\n",
    "\n",
    "# 데이터 전처리\n",
    "# 255를 0~1로 압축 시간을 감소 시켜 보려 했으나 큰 차이가 없네\n",
    "def 전처리함수(i, 정답):\n",
    "    i = tf.cast(i/255.0, tf.float32)\n",
    "    return i, 정답\n",
    "\n",
    "train_ds = train_ds.map(전처리함수)\n",
    "val_ds = val_ds.map(전처리함수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c791627",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.08425054 0.02934857 0.02542701]\n",
      "   [0.0788603  0.02395833 0.02003676]\n",
      "   [0.09209559 0.04895834 0.03327206]\n",
      "   ...\n",
      "   [0.06710516 0.02360026 0.00803654]\n",
      "   [0.07450981 0.01960784 0.01568628]\n",
      "   [0.00392923 0.00803654 0.00392923]]\n",
      "\n",
      "  [[0.1010972  0.0501168  0.02658739]\n",
      "   [0.119267   0.06828661 0.0447572 ]\n",
      "   [0.06590265 0.03845167 0.01492226]\n",
      "   ...\n",
      "   [0.07071079 0.02720588 0.01164216]\n",
      "   [0.06977443 0.01487247 0.0109509 ]\n",
      "   [0.00349839 0.01146408 0.00509153]]\n",
      "\n",
      "  [[0.09571078 0.04473039 0.01335784]\n",
      "   [0.09761029 0.0466299  0.01525735]\n",
      "   [0.07900965 0.066142   0.03922909]\n",
      "   ...\n",
      "   [0.07178692 0.02703546 0.01188726]\n",
      "   [0.0753753  0.02147863 0.01722197]\n",
      "   [0.00857843 0.01602137 0.00982307]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.3947572  0.32857114 0.24108073]\n",
      "   [0.46586245 0.3835095  0.26279873]\n",
      "   [0.5416322  0.4666322  0.34874004]\n",
      "   ...\n",
      "   [0.46569967 0.29682714 0.0887389 ]\n",
      "   [0.37026656 0.20948224 0.0077742 ]\n",
      "   [0.4407437  0.29987362 0.05557215]]\n",
      "\n",
      "  [[0.48482114 0.40479666 0.29657438]\n",
      "   [0.51422524 0.4201076  0.27317134]\n",
      "   [0.49564952 0.43633577 0.31452206]\n",
      "   ...\n",
      "   [0.45350987 0.29272556 0.07311773]\n",
      "   [0.45362094 0.2897729  0.09197878]\n",
      "   [0.44724074 0.3043486  0.08106426]]\n",
      "\n",
      "  [[0.50129825 0.42721546 0.31569585]\n",
      "   [0.5409371  0.47267157 0.33688724]\n",
      "   [0.3788737  0.31072688 0.1809666 ]\n",
      "   ...\n",
      "   [0.45226717 0.29503676 0.06450291]\n",
      "   [0.40211588 0.28054726 0.05959138]\n",
      "   [0.36742684 0.234645   0.05584597]]]\n",
      "\n",
      "\n",
      " [[[0.21224533 0.24030043 0.21281882]\n",
      "   [0.25968328 0.35149837 0.28968674]\n",
      "   [0.23468712 0.3047727  0.24202761]\n",
      "   ...\n",
      "   [0.5584243  0.7282772  0.50805664]\n",
      "   [0.5104167  0.67634803 0.47965688]\n",
      "   [0.5078345  0.68430513 0.46861884]]\n",
      "\n",
      "  [[0.25026998 0.32710823 0.27319622]\n",
      "   [0.16403474 0.25218004 0.18261719]\n",
      "   [0.17885742 0.2684781  0.18494754]\n",
      "   ...\n",
      "   [0.5279192  0.68086034 0.4573309 ]\n",
      "   [0.5071347  0.65717965 0.45512888]\n",
      "   [0.4865598  0.6630304  0.44734412]]\n",
      "\n",
      "  [[0.26820427 0.34848633 0.28246304]\n",
      "   [0.25512886 0.29269013 0.22800149]\n",
      "   [0.38479245 0.43947896 0.35697284]\n",
      "   ...\n",
      "   [0.47438726 0.6682598  0.4125    ]\n",
      "   [0.45499867 0.6449496  0.41664082]\n",
      "   [0.47118375 0.64765435 0.43196806]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5489947  0.47014686 0.40326574]\n",
      "   [0.5503849  0.46976104 0.38483456]\n",
      "   [0.5905599  0.50649124 0.4409888 ]\n",
      "   ...\n",
      "   [0.61251915 0.63558614 0.5842697 ]\n",
      "   [0.616794   0.6524663  0.56972176]\n",
      "   [0.59027743 0.5977529  0.532802  ]]\n",
      "\n",
      "  [[0.4929477  0.41059473 0.33608493]\n",
      "   [0.43450233 0.3521494  0.2776396 ]\n",
      "   [0.6277708  0.54541785 0.47090802]\n",
      "   ...\n",
      "   [0.62132543 0.6487764  0.5860313 ]\n",
      "   [0.3396781  0.39180645 0.31198204]\n",
      "   [0.49007735 0.51752836 0.4469401 ]]\n",
      "\n",
      "  [[0.50531363 0.4229607  0.3484509 ]\n",
      "   [0.43097234 0.3486194  0.2741096 ]\n",
      "   [0.5894234  0.5070705  0.4325607 ]\n",
      "   ...\n",
      "   [0.6366527  0.66339904 0.5956294 ]\n",
      "   [0.4930913  0.54220283 0.47806948]\n",
      "   [0.55831707 0.5954494  0.52032685]]]\n",
      "\n",
      "\n",
      " [[[0.20985371 0.36276424 0.288377  ]\n",
      "   [0.20896906 0.3658318  0.27153033]\n",
      "   [0.15934436 0.31071922 0.24513634]\n",
      "   ...\n",
      "   [0.1956495  0.32882965 0.23140319]\n",
      "   [0.12913603 0.2522327  0.21627603]\n",
      "   [0.16037071 0.29373467 0.18767999]]\n",
      "\n",
      "  [[0.1639323  0.31684282 0.24640778]\n",
      "   [0.2490311  0.40206417 0.3192517 ]\n",
      "   [0.1102137  0.25921416 0.20200291]\n",
      "   ...\n",
      "   [0.09950598 0.23268612 0.13902803]\n",
      "   [0.00718444 0.12401195 0.07252987]\n",
      "   [0.05546875 0.18883272 0.08383119]]\n",
      "\n",
      "  [[0.0197572  0.16875    0.11012945]\n",
      "   [0.06759344 0.22054611 0.14581801]\n",
      "   [0.01508502 0.16065411 0.11797641]\n",
      "   ...\n",
      "   [0.09090839 0.22032017 0.13796721]\n",
      "   [0.06006817 0.18947993 0.11497013]\n",
      "   [0.06526119 0.19762178 0.09952129]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.71609604 0.7945274  0.83766466]\n",
      "   [0.64351255 0.7219439  0.76508117]\n",
      "   [0.57228863 0.64679843 0.7017004 ]\n",
      "   ...\n",
      "   [0.10821079 0.1317402  0.1317402 ]\n",
      "   [0.19043735 0.2059398  0.20183441]\n",
      "   [0.12639016 0.13031173 0.11070389]]\n",
      "\n",
      "  [[0.6351486  0.69887406 0.7606388 ]\n",
      "   [0.5928194  0.65654486 0.7148782 ]\n",
      "   [0.62588465 0.69290745 0.73350567]\n",
      "   ...\n",
      "   [0.05800781 0.08153722 0.08153722]\n",
      "   [0.14367723 0.15917969 0.1550743 ]\n",
      "   [0.14069393 0.1446155  0.12500766]]\n",
      "\n",
      "  [[0.6605277  0.71935123 0.79389936]\n",
      "   [0.5743528  0.6370979  0.6959214 ]\n",
      "   [0.51290977 0.57957643 0.61125535]\n",
      "   ...\n",
      "   [0.11616881 0.13969822 0.13969822]\n",
      "   [0.1227788  0.13828126 0.13417585]\n",
      "   [0.12457874 0.12850031 0.10889246]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.31213236 0.33566177 0.32781863]\n",
      "   [0.30980393 0.33333334 0.3254902 ]\n",
      "   [0.3019608  0.3254902  0.31764707]\n",
      "   ...\n",
      "   [0.7286152  0.72469366 0.6462622 ]\n",
      "   [0.7411765  0.72156864 0.64705884]\n",
      "   [0.74065566 0.7210478  0.646538  ]]\n",
      "\n",
      "  [[0.3050245  0.32855392 0.32071078]\n",
      "   [0.30361232 0.32714173 0.3192986 ]\n",
      "   [0.29411766 0.31764707 0.30980393]\n",
      "   ...\n",
      "   [0.7300341  0.72611254 0.64375955]\n",
      "   [0.7411765  0.72156864 0.6431373 ]\n",
      "   [0.7522356  0.7326277  0.6541963 ]]\n",
      "\n",
      "  [[0.29723403 0.32076344 0.3129203 ]\n",
      "   [0.30008712 0.32361653 0.3157734 ]\n",
      "   [0.29099265 0.31452206 0.30667892]\n",
      "   ...\n",
      "   [0.7180329  0.7180329  0.62367016]\n",
      "   [0.74105394 0.72156864 0.6349265 ]\n",
      "   [0.7396446  0.7201593  0.63351715]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.9781164  1.         0.99989945]\n",
      "   [0.60404414 0.55759805 0.41311276]\n",
      "   [0.6202388  0.58798444 0.44713828]\n",
      "   ...\n",
      "   [0.45180187 0.4945408  0.44083372]\n",
      "   [0.6225232  0.697033   0.6225232 ]\n",
      "   [0.63690066 0.7014533  0.6315698 ]]\n",
      "\n",
      "  [[0.987928   0.9982824  0.9996917 ]\n",
      "   [0.595616   0.5442153  0.40138155]\n",
      "   [0.6139658  0.57395357 0.4313582 ]\n",
      "   ...\n",
      "   [0.396875   0.43961397 0.38590688]\n",
      "   [0.6231005  0.6976103  0.6231005 ]\n",
      "   [0.62628675 0.69083947 0.6209559 ]]\n",
      "\n",
      "  [[0.98320985 0.99929535 0.9675236 ]\n",
      "   [0.5380831  0.48740906 0.38544825]\n",
      "   [0.5382353  0.52254903 0.38449755]\n",
      "   ...\n",
      "   [0.3453479  0.3884852  0.32653666]\n",
      "   [0.60821176 0.6788     0.62751323]\n",
      "   [0.63363874 0.663602   0.6054831 ]]]\n",
      "\n",
      "\n",
      " [[[0.2490476  0.21543854 0.14540178]\n",
      "   [0.29543504 0.26182598 0.19178921]\n",
      "   [0.32882965 0.2856924  0.19941789]\n",
      "   ...\n",
      "   [0.43974537 0.42798066 0.29072577]\n",
      "   [0.416889   0.416889   0.27571255]\n",
      "   [0.3959559  0.3959559  0.2547794 ]]\n",
      "\n",
      "  [[0.30463412 0.27718315 0.16345765]\n",
      "   [0.29375    0.266299   0.15257353]\n",
      "   [0.348398   0.30918232 0.20329997]\n",
      "   ...\n",
      "   [0.4425068  0.43074208 0.30128676]\n",
      "   [0.43465766 0.43465766 0.2934812 ]\n",
      "   [0.40965864 0.40965864 0.26848215]]\n",
      "\n",
      "  [[0.31354168 0.28275123 0.19080882]\n",
      "   [0.3204044  0.28903186 0.19883579]\n",
      "   [0.35741878 0.32212466 0.20839916]\n",
      "   ...\n",
      "   [0.47193962 0.4590198  0.33796746]\n",
      "   [0.44950095 0.44775462 0.30716026]\n",
      "   [0.41934526 0.41759896 0.2770046 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.11200071 0.09169251 0.07012389]\n",
      "   [0.11648548 0.11713772 0.08613281]\n",
      "   [0.08008578 0.08342525 0.0520527 ]\n",
      "   ...\n",
      "   [0.07274649 0.11183962 0.0806509 ]\n",
      "   [0.06227668 0.08580609 0.07796296]\n",
      "   [0.06158088 0.08511029 0.07726716]]\n",
      "\n",
      "  [[0.08124115 0.06777655 0.06943096]\n",
      "   [0.07214379 0.07998693 0.07379821]\n",
      "   [0.08121936 0.0890625  0.07503064]\n",
      "   ...\n",
      "   [0.05496323 0.07447917 0.05110294]\n",
      "   [0.05398978 0.06183292 0.05791135]\n",
      "   [0.05655637 0.06439951 0.06047794]]\n",
      "\n",
      "  [[0.07720588 0.06936274 0.07328431]\n",
      "   [0.06333511 0.05549197 0.05941354]\n",
      "   [0.06658792 0.08227419 0.08619576]\n",
      "   ...\n",
      "   [0.04892769 0.06838235 0.05275735]\n",
      "   [0.0627451  0.06666667 0.04705882]\n",
      "   [0.06443015 0.06835172 0.04874387]]]\n",
      "\n",
      "\n",
      " [[[0.5942227  0.61775213 0.6051909 ]\n",
      "   [0.58540875 0.6050166  0.6167813 ]\n",
      "   [0.5461658  0.5764268  0.57422954]\n",
      "   ...\n",
      "   [0.50621915 0.5139704  0.50220996]\n",
      "   [0.46492824 0.46492824 0.46492824]\n",
      "   [0.5220002  0.53768647 0.54473305]]\n",
      "\n",
      "  [[0.6607259  0.6842553  0.67169404]\n",
      "   [0.56789213 0.5875     0.5992647 ]\n",
      "   [0.5018504  0.52537984 0.52537984]\n",
      "   ...\n",
      "   [0.46458885 0.47234008 0.4605141 ]\n",
      "   [0.44973528 0.45365685 0.434049  ]\n",
      "   [0.4804209  0.49610716 0.49553987]]\n",
      "\n",
      "  [[0.61585265 0.64112836 0.62868536]\n",
      "   [0.55594844 0.5749742  0.5855746 ]\n",
      "   [0.58630395 0.60861695 0.601382  ]\n",
      "   ...\n",
      "   [0.45547163 0.46210292 0.45076257]\n",
      "   [0.4514883  0.45657408 0.42578363]\n",
      "   [0.5177301  0.53710604 0.51543665]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.44967183 0.5045738  0.5045738 ]\n",
      "   [0.36575714 0.4206591  0.4206591 ]\n",
      "   [0.53359425 0.57005256 0.5890783 ]\n",
      "   ...\n",
      "   [0.49659926 0.5320329  0.52152437]\n",
      "   [0.46548882 0.5108013  0.51371187]\n",
      "   [0.21553189 0.24079016 0.24187562]]\n",
      "\n",
      "  [[0.35070467 0.40560663 0.40560663]\n",
      "   [0.51756734 0.5724693  0.5724693 ]\n",
      "   [0.46829045 0.50750613 0.5114277 ]\n",
      "   ...\n",
      "   [0.28232422 0.32544854 0.3020893 ]\n",
      "   [0.48637217 0.5105143  0.5261087 ]\n",
      "   [0.25795275 0.2628004  0.27984262]]\n",
      "\n",
      "  [[0.3937658  0.41839814 0.42792633]\n",
      "   [0.53075    0.53761965 0.5315762 ]\n",
      "   [0.5438589  0.58307457 0.579153  ]\n",
      "   ...\n",
      "   [0.2781695  0.31331044 0.34088397]\n",
      "   [0.5119141  0.5354435  0.5291322 ]\n",
      "   [0.26094708 0.28763214 0.29703775]]]], shape=(64, 64, 64, 3), dtype=float32) tf.Tensor(\n",
      "[1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0\n",
      " 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0 0 1], shape=(64,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "for i, a in train_ds.take(1):\n",
    "    print(i, a)\n",
    "#     plt.imshow(i[0].numpy().astype('uint8'))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dee9a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "313/313 [==============================] - 171s 545ms/step - loss: 0.6173 - accuracy: 0.6517 - val_loss: 0.5617 - val_accuracy: 0.7124\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 99s 318ms/step - loss: 0.5170 - accuracy: 0.7454 - val_loss: 0.4806 - val_accuracy: 0.7732\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 92s 295ms/step - loss: 0.4679 - accuracy: 0.7783 - val_loss: 0.4776 - val_accuracy: 0.7786\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 91s 290ms/step - loss: 0.4282 - accuracy: 0.8052 - val_loss: 0.4275 - val_accuracy: 0.8098\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 92s 294ms/step - loss: 0.3987 - accuracy: 0.8174 - val_loss: 0.3862 - val_accuracy: 0.8236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dbe7ccda60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(64, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Dropout(0.2), # 오버피팅 완화 기능 dropout, 20% 제거\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=val_ds,epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
